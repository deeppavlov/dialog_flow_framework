{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ef47b2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Core: 3. Responses\n",
    "\n",
    "This tutorial shows different options for setting responses.\n",
    "\n",
    "Here, [responses](../apiref/dff.script.responses.std_responses.rst)\n",
    "that allow giving custom answers to users are shown.\n",
    "\n",
    "Let's do all the necessary imports from DFF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695d40ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:00:05.568142Z",
     "iopub.status.busy": "2024-03-01T20:00:05.567921Z",
     "iopub.status.idle": "2024-03-01T20:00:07.808084Z",
     "shell.execute_reply": "2024-03-01T20:00:07.807231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# installing dependencies\n",
    "%pip install -q dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844ff4c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:00:07.811324Z",
     "iopub.status.busy": "2024-03-01T20:00:07.810912Z",
     "iopub.status.idle": "2024-03-01T20:00:08.512342Z",
     "shell.execute_reply": "2024-03-01T20:00:08.511331Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "from dff.script import TRANSITIONS, RESPONSE, Context, Message\n",
    "import dff.script.responses as rsp\n",
    "import dff.script.conditions as cnd\n",
    "\n",
    "from dff.pipeline import Pipeline\n",
    "from dff.utils.testing.common import (\n",
    "    check_happy_path,\n",
    "    is_interactive_mode,\n",
    "    run_interactive_mode,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd213ef",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "The response can be set by Callable or *Message:\n",
    "\n",
    "* Callable objects. If the object is callable it must have a special signature:\n",
    "\n",
    "        func(ctx: Context, pipeline: Pipeline) -> Message\n",
    "\n",
    "* *Message objects. If the object is *Message\n",
    "    it will be returned by the agent as a response.\n",
    "\n",
    "\n",
    "The functions to be used in the `toy_script` are declared here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d40f869f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:00:08.516021Z",
     "iopub.status.busy": "2024-03-01T20:00:08.515367Z",
     "iopub.status.idle": "2024-03-01T20:00:08.521897Z",
     "shell.execute_reply": "2024-03-01T20:00:08.521251Z"
    }
   },
   "outputs": [],
   "source": [
    "def cannot_talk_about_topic_response(ctx: Context, _: Pipeline) -> Message:\n",
    "    request = ctx.last_request\n",
    "    if request is None or request.text is None:\n",
    "        topic = None\n",
    "    else:\n",
    "        topic_pattern = re.compile(r\"(.*talk about )(.*)\\.\")\n",
    "        topic = topic_pattern.findall(request.text)\n",
    "        topic = topic and topic[0] and topic[0][-1]\n",
    "    if topic:\n",
    "        return Message(f\"Sorry, I can not talk about {topic} now.\")\n",
    "    else:\n",
    "        return Message(\"Sorry, I can not talk about that now.\")\n",
    "\n",
    "\n",
    "def upper_case_response(response: Message):\n",
    "    # wrapper for internal response function\n",
    "    def func(_: Context, __: Pipeline) -> Message:\n",
    "        if response.text is not None:\n",
    "            response.text = response.text.upper()\n",
    "        return response\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "def fallback_trace_response(ctx: Context, _: Pipeline) -> Message:\n",
    "    return Message(\n",
    "        misc={\n",
    "            \"previous_node\": list(ctx.labels.values())[-2],\n",
    "            \"last_request\": ctx.last_request,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02db0dfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:00:08.524891Z",
     "iopub.status.busy": "2024-03-01T20:00:08.524312Z",
     "iopub.status.idle": "2024-03-01T20:00:08.534295Z",
     "shell.execute_reply": "2024-03-01T20:00:08.533639Z"
    }
   },
   "outputs": [],
   "source": [
    "toy_script = {\n",
    "    \"greeting_flow\": {\n",
    "        \"start_node\": {  # This is an initial node,\n",
    "            # it doesn't need a `RESPONSE`.\n",
    "            RESPONSE: Message(),\n",
    "            TRANSITIONS: {\"node1\": cnd.exact_match(Message(\"Hi\"))},\n",
    "            # If \"Hi\" == request of user then we make the transition\n",
    "        },\n",
    "        \"node1\": {\n",
    "            RESPONSE: rsp.choice(\n",
    "                [\n",
    "                    Message(\"Hi, what is up?\"),\n",
    "                    Message(\"Hello, how are you?\"),\n",
    "                ]\n",
    "            ),\n",
    "            # Random choice from candidate list.\n",
    "            TRANSITIONS: {\n",
    "                \"node2\": cnd.exact_match(Message(\"I'm fine, how are you?\"))\n",
    "            },\n",
    "        },\n",
    "        \"node2\": {\n",
    "            RESPONSE: Message(\"Good. What do you want to talk about?\"),\n",
    "            TRANSITIONS: {\n",
    "                \"node3\": cnd.exact_match(Message(\"Let's talk about music.\"))\n",
    "            },\n",
    "        },\n",
    "        \"node3\": {\n",
    "            RESPONSE: cannot_talk_about_topic_response,\n",
    "            TRANSITIONS: {\"node4\": cnd.exact_match(Message(\"Ok, goodbye.\"))},\n",
    "        },\n",
    "        \"node4\": {\n",
    "            RESPONSE: upper_case_response(Message(\"bye\")),\n",
    "            TRANSITIONS: {\"node1\": cnd.exact_match(Message(\"Hi\"))},\n",
    "        },\n",
    "        \"fallback_node\": {  # We get to this node\n",
    "            # if an error occurred while the agent was running.\n",
    "            RESPONSE: fallback_trace_response,\n",
    "            TRANSITIONS: {\"node1\": cnd.exact_match(Message(\"Hi\"))},\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "# testing\n",
    "happy_path = (\n",
    "    (\n",
    "        Message(\"Hi\"),\n",
    "        Message(\"Hello, how are you?\"),\n",
    "    ),  # start_node -> node1\n",
    "    (\n",
    "        Message(\"I'm fine, how are you?\"),\n",
    "        Message(\"Good. What do you want to talk about?\"),\n",
    "    ),  # node1 -> node2\n",
    "    (\n",
    "        Message(\"Let's talk about music.\"),\n",
    "        Message(\"Sorry, I can not talk about music now.\"),\n",
    "    ),  # node2 -> node3\n",
    "    (Message(\"Ok, goodbye.\"), Message(\"BYE\")),  # node3 -> node4\n",
    "    (Message(\"Hi\"), Message(\"Hello, how are you?\")),  # node4 -> node1\n",
    "    (\n",
    "        Message(\"stop\"),\n",
    "        Message(\n",
    "            misc={\n",
    "                \"previous_node\": (\"greeting_flow\", \"node1\"),\n",
    "                \"last_request\": Message(\"stop\"),\n",
    "            }\n",
    "        ),\n",
    "    ),\n",
    "    # node1 -> fallback_node\n",
    "    (\n",
    "        Message(\"one\"),\n",
    "        Message(\n",
    "            misc={\n",
    "                \"previous_node\": (\"greeting_flow\", \"fallback_node\"),\n",
    "                \"last_request\": Message(\"one\"),\n",
    "            }\n",
    "        ),\n",
    "    ),  # f_n->f_n\n",
    "    (\n",
    "        Message(\"help\"),\n",
    "        Message(\n",
    "            misc={\n",
    "                \"previous_node\": (\"greeting_flow\", \"fallback_node\"),\n",
    "                \"last_request\": Message(\"help\"),\n",
    "            }\n",
    "        ),\n",
    "    ),  # f_n->f_n\n",
    "    (\n",
    "        Message(\"nope\"),\n",
    "        Message(\n",
    "            misc={\n",
    "                \"previous_node\": (\"greeting_flow\", \"fallback_node\"),\n",
    "                \"last_request\": Message(\"nope\"),\n",
    "            }\n",
    "        ),\n",
    "    ),  # f_n->f_n\n",
    "    (\n",
    "        Message(\"Hi\"),\n",
    "        Message(\"Hi, what is up?\"),\n",
    "    ),  # fallback_node -> node1\n",
    "    (\n",
    "        Message(\"I'm fine, how are you?\"),\n",
    "        Message(\"Good. What do you want to talk about?\"),\n",
    "    ),  # node1 -> node2\n",
    "    (\n",
    "        Message(\"Let's talk about music.\"),\n",
    "        Message(\"Sorry, I can not talk about music now.\"),\n",
    "    ),  # node2 -> node3\n",
    "    (Message(\"Ok, goodbye.\"), Message(\"BYE\")),  # node3 -> node4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8041d22a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T20:00:08.537119Z",
     "iopub.status.busy": "2024-03-01T20:00:08.536901Z",
     "iopub.status.idle": "2024-03-01T20:00:08.562365Z",
     "shell.execute_reply": "2024-03-01T20:00:08.561632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(user) >>> text='Hi'\n",
      " (bot) <<< text='Hello, how are you?'\n",
      "(user) >>> text='I'm fine, how are you?'\n",
      " (bot) <<< text='Good. What do you want to talk about?'\n",
      "(user) >>> text='Let's talk about music.'\n",
      " (bot) <<< text='Sorry, I can not talk about music now.'\n",
      "(user) >>> text='Ok, goodbye.'\n",
      " (bot) <<< text='BYE'\n",
      "(user) >>> text='Hi'\n",
      " (bot) <<< text='Hello, how are you?'\n",
      "(user) >>> text='stop'\n",
      " (bot) <<< misc='{'previous_node': ('greeting_flow', 'node1'), 'last_request': {'text': 'stop'}}'\n",
      "(user) >>> text='one'\n",
      " (bot) <<< misc='{'previous_node': ('greeting_flow', 'fallback_node'), 'last_request': {'text': 'one'}}'\n",
      "(user) >>> text='help'\n",
      " (bot) <<< misc='{'previous_node': ('greeting_flow', 'fallback_node'), 'last_request': {'text': 'help'}}'\n",
      "(user) >>> text='nope'\n",
      " (bot) <<< misc='{'previous_node': ('greeting_flow', 'fallback_node'), 'last_request': {'text': 'nope'}}'\n",
      "(user) >>> text='Hi'\n",
      " (bot) <<< text='Hi, what is up?'\n",
      "(user) >>> text='I'm fine, how are you?'\n",
      " (bot) <<< text='Good. What do you want to talk about?'\n",
      "(user) >>> text='Let's talk about music.'\n",
      " (bot) <<< text='Sorry, I can not talk about music now.'\n",
      "(user) >>> text='Ok, goodbye.'\n",
      " (bot) <<< text='BYE'\n"
     ]
    }
   ],
   "source": [
    "random.seed(31415)  # predestination of choice\n",
    "\n",
    "\n",
    "pipeline = Pipeline.from_script(\n",
    "    toy_script,\n",
    "    start_label=(\"greeting_flow\", \"start_node\"),\n",
    "    fallback_label=(\"greeting_flow\", \"fallback_node\"),\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_happy_path(pipeline, happy_path)\n",
    "    if is_interactive_mode():\n",
    "        run_interactive_mode(pipeline)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
